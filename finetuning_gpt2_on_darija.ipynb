{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev81ZCO4yCMM"
      },
      "source": [
        "scape data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jw8aKg23UvG",
        "outputId": "f2ccc8ec-e547-456c-edbf-50d676fb0a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=15c26c0fb8bce411eaa296a93c57bce748ce24cf7a647dc08f3f28ee01018aa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.10 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install beautifulsoup4 feedparser requests\n",
        "# Iterate over each post link\n",
        "import feedparser\n",
        "import requests\n",
        "import os.path\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TDELWvByE42",
        "outputId": "dd9a179a-6cc7-4a50-fbc1-41e3d383dc56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.9esa.com/2023/07/la-tojbirni-3ala-7obik-20.html', 'https://www.9esa.com/2023/07/3ers-dib-28.html', 'https://www.9esa.com/2023/07/3asifa-hawja2-28.html', 'https://www.9esa.com/2023/07/ghirk-ma-y7lali-28.html', 'https://www.9esa.com/2023/07/la-tojbirni-3ala-7obik-19.html', 'https://www.9esa.com/2023/07/3ers-dib-27.html', 'https://www.9esa.com/2023/07/3asifa-hawja2-27.html', 'https://www.9esa.com/2023/07/ghirk-ma-y7lali-27.html', 'https://www.9esa.com/2023/07/la-tojbirni-3ala-7obik-18.html', 'https://www.9esa.com/2023/07/3ers-dib-26.html', 'https://www.9esa.com/2023/07/3asifa-hawja2-26.html', 'https://www.9esa.com/2023/07/ghirk-ma-y7lali-26.html', 'https://www.9esa.com/2023/07/la-tojbirni-3ala-7obik-17.html', 'https://www.9esa.com/2023/07/3ers-dib-25.html', 'https://www.9esa.com/2023/07/3asifa-hawja2-25.html', 'https://www.9esa.com/2023/07/ghirk-ma-y7lali-25.html', 'https://www.9esa.com/2023/07/la-tojbirni-3ala-7obik-16.html', 'https://www.9esa.com/2023/07/3ers-dib-24.html', 'https://www.9esa.com/2023/07/3asifa-hawja2-24.html', 'https://www.9esa.com/2023/07/ghirk-ma-y7lali-24.html', 'https://www.9esa.com/2023/06/la-tojbirni-3ala-7obik-15.html', 'https://www.9esa.com/2023/06/3ers-dib-23.html', 'https://www.9esa.com/2023/06/3asifa-hawja2-23.html', 'https://www.9esa.com/2023/06/ghirk-ma-y7lali-23.html', 'https://www.9esa.com/2023/06/la-tojbirni-3ala-7obik-14.html']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the RSS feed file\n",
        "with open(\"/content/drive/MyDrive/9esa.com_rss.xml\", 'r', encoding='utf-8') as file:\n",
        "    sentences = file.read()\n",
        "data_file = '/content/drive/MyDrive/datasets/dataset_darija_stories.txt'\n",
        "# Parse the RSS feed\n",
        "feed = feedparser.parse(sentences)\n",
        "# Extract the post links\n",
        "post_links = [entry.link for entry in feed.entries]\n",
        "print(post_links)\n",
        "# Print the post links\n",
        "for link in post_links:\n",
        "    post_response = requests.get(link)\n",
        "    if post_response.status_code != 200:\n",
        "        print(\"Error accessing post:\", link)\n",
        "        continue\n",
        "\n",
        "    # Create BeautifulSoup object with the post's HTML content\n",
        "    post_soup = BeautifulSoup(post_response.content, 'html.parser')\n",
        "\n",
        "    # Find all \".Noto p\" elements and extract their text\n",
        "    paragraphs = post_soup.select('.Noto p')\n",
        "    text = '\\n'.join([p.get_text(strip=True) for p in paragraphs])\n",
        "\n",
        "    # Save the extracted text to the output file\n",
        "    with open(data_file, 'a', encoding='utf-8') as file:\n",
        "      file.write(text + '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwYoI-caZKDy"
      },
      "source": [
        "> **Finetuning gpt2 on darija sentence's with tests included**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "luXwmWV_L31z",
        "outputId": "8ace7320-e022-46b8-b5b9-b9cf55ff2a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lvfFbUnL_Uz",
        "outputId": "5ad9563f-02c0-4559-e51a-b493db39a9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision transformers\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjJ94tBYMD75",
        "outputId": "826ae075-1358-4f5b-8d28-69ceca8ca88d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['سأخبرك سرا', 'إنني أخون كبريائي في الخفاء', 'وأتبع أخبارك ليطمئن قلبي عليك', 'اشتقت لك بصمت  فهل يصلك ضجيج حنيني', 'رسالتها كانت كالبلسم على جروحوو و رووحو كان في قمة احتيااجو ليها تمنى يعيش معاها ولو غير لحظة هانيين و تكمل فرحتهم لكن الطرووف دائما ضده اكيد حتى هو ندم على تهوره و زوااجو يمكن مكانش غايظلم معاه زوج ديال النااس معاه وحدة تيموت عليها و هي مزالها متضااربة مع احساسها و وحدة تتبغييه و هو تايحس فقط بالواجب تجاهها', 'اما مريم وصلت لمرحة اصبحت تتقول حزنت بما يكفي وبكيت على الاطلال زمنا طويلا و جا الوقت فين تفتح الباب لقلبها و تعطي فرصة لدااك ولد النااس يدخل ليه  لكن صدمة الاخيرة ديال فائزة خلاتها تفكر فحااجة وحدة هي الفرااق غاافلة على ان هااد الرجل مااشي وقت لي قالت لو اجي يجي تيجري و وقت لي بغات تقوول ليه سالينا غايمشي بكل سهوولة الانساان عندوو طااقة التحمل محدودة و خصووصا الرجال تتجي وااحد اللحظة الغضب تيعمي على العين الانساان متيبقاش عارف شنو تيدير لكن هاد المرة حتى طلب الطلاق ندمات عليه الاياام لي فااتو متيزورهاش كيف عادتوو مرو كانو كانهم دهر هل هو الشووق الحنين اكيد الندم', 'تنهد و رجع رااسو للور تيقرا رساالتها و يعااودها عدة مراات فتح صوورة الملف الشخصي لقاها حااطة صوورة ديال يديهم بزوجكانو صورها فالبحر علا حوااجبوو باستغرااب و ضور لها فالحين', 'صوت رنين الهاتف جعلها تفتح عينيها على وسعهم كانت تتسنى غير رساالة ناضت جلسات و عدلات ضهرها على المخدة شافت فاسمو منور الشاشة طويييلا عاد جااوباتو', 'مريم بونسواغ', 'رحيم سااد صمت طويل قبل ما يجاوبها بصوت اجش اش مسهرك لهاد الوقت']\n"
          ]
        }
      ],
      "source": [
        "# !jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000\n",
        "# Step 1: Load and preprocess the dataset\n",
        "data_file = '/content/drive/MyDrive/datasets/dataset_darija_stories.txt'\n",
        "\n",
        "with open(data_file, 'r', encoding='utf-8') as file:\n",
        "    sentences = file.read().splitlines()\n",
        "    sentences = [el.replace('\"', '') for el in sentences]\n",
        "    print(cleaned_sentences[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "gxO0dp3-ZgQi",
        "outputId": "7c07583e-50cf-4b5e-f1b1-908b01c1d0ed"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-69d2b4f419a3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set up GPU if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 2: Tokenize the sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# Set up GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 2: Tokenize the sentences\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenized_sentences = [tokenizer.encode(sentence) for sentence in sentences]\n",
        "\n",
        "# Step 3: Define a custom PyTorch Dataset\n",
        "class DarijaDataset(Dataset):\n",
        "    def __init__(self, tokenized_sentences):\n",
        "        self.tokenized_sentences = tokenized_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.tokenized_sentences[idx])\n",
        "\n",
        "# Step 4: Prepare the GPT-2 model\n",
        "config = GPT2Config.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
        "model.to(device)\n",
        "\n",
        "# Step 5: Set up the fine-tuning pipeline\n",
        "dataset = DarijaDataset(tokenized_sentences)\n",
        "batch_size = 4\n",
        "num_epochs = 3\n",
        "\n",
        "# Define custom collate function to pad sequences dynamically\n",
        "def collate_fn(batch):\n",
        "    padded_batch = pad_sequence(batch, batch_first=True)\n",
        "    return padded_batch\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Step 6: Fine-tune the GPT-2 model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        outputs = model.forward(input_ids=batch[:, :-1], labels=batch[:, 1:])\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch + 1} - Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Step 7: Save the fine-tuned model\n",
        "output_dir = '/content/drive/MyDrive/dataset/fine_tuned_model'\n",
        "model.save_pretrained(output_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hGruilklru7"
      },
      "source": [
        "__*now let test our model*__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar6FummElmYO"
      },
      "outputs": [],
      "source": [
        "# Step 8: Inference and generation using the fine-tuned model\n",
        "Load the fine-tuned model for future use\n",
        "fine_tuned_model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "\n",
        "# Generate text using the fine-tuned model\n",
        "inputs = tokenizer.encode(\"Your input prompt\", return_tensors=\"pt\").to(device)\n",
        "generated_text = fine_tuned_model.generate(inputs, max_length=100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}